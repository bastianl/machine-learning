{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Supervised Learning\n",
    "### Building a Student Intervention System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification vs Regression\n",
    "\n",
    "Your goal is to identify students who might need early intervention - which type of supervised machine learning problem is this, classification or regression? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: This seems like a classification task, as we are are predicting a binary output (pass or fail) as opposed to a continuous output, for which regression would be more suited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring the Data\n",
    "\n",
    "Let's go ahead and read in the student dataset first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student data read successfully!\n"
     ]
    }
   ],
   "source": [
    "# Read student data\n",
    "student_data = pd.read_csv(\"student_intervention/student-data.csv\")\n",
    "print(\"Student data read successfully!\")\n",
    "# Note: The last column 'passed' is the target/label, all other are feature columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, can you find out the following facts about the dataset?\n",
    "- Total number of students\n",
    "- Number of students who passed\n",
    "- Number of students who failed\n",
    "- Graduation rate of the class (%)\n",
    "- Number of features\n",
    "\n",
    "_Use the code block below to compute these values. Instructions/steps are marked using **TODO**s._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of students: 395\n",
      "Number of students who passed: 265\n",
      "Number of students who failed: 130\n",
      "Number of features: 30\n",
      "Graduation rate of the class: 0.67%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute desired values - replace each '?' with an appropriate expression/function call\n",
    "n_students = len(student_data)\n",
    "n_features = len(student_data.columns) - 1  # exclude 'passed' column\n",
    "n_passed = np.sum(student_data['passed'] == 'yes')\n",
    "n_failed = np.sum(student_data['passed'] == 'no')\n",
    "grad_rate = n_passed / (n_passed + n_failed)\n",
    "print(\"Total number of students: {}\".format(n_students))\n",
    "print(\"Number of students who passed: {}\".format(n_passed))\n",
    "print(\"Number of students who failed: {}\".format(n_failed))\n",
    "print(\"Number of features: {}\".format(n_features))\n",
    "print(\"Graduation rate of the class: {:.2f}%\".format(grad_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparing the Data\n",
    "In this section, we will prepare the data for modeling, training and testing.\n",
    "\n",
    "### Identify feature and target columns\n",
    "It is often the case that the data you obtain contains non-numeric features. This can be a problem, as most machine learning algorithms expect numeric data to perform computations with.\n",
    "\n",
    "Let's first separate our data into feature and target columns, and see if any features are non-numeric.<br/>\n",
    "**Note**: For this dataset, the last column (`'passed'`) is the target or label we are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature column(s):-\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "Target column: passed\n"
     ]
    }
   ],
   "source": [
    "# Extract feature (X) and target (y) columns\n",
    "feature_cols = list(student_data.columns[:-1])  # all columns but last are features\n",
    "target_col = student_data.columns[-1]  # last column is the target/label\n",
    "print(\"Feature column(s):-\\n{}\".format(feature_cols))\n",
    "print(\"Target column: {}\".format(target_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess feature columns\n",
    "\n",
    "As you can see, there are several non-numeric columns that need to be converted! Many of them are simply `yes`/`no`, e.g. `internet`. These can be reasonably converted into `1`/`0` (binary) values.\n",
    "\n",
    "Other columns, like `Mjob` and `Fjob`, have more than two values, and are known as _categorical variables_. The recommended way to handle such a column is to create as many columns as possible values (e.g. `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc.), and assign a `1` to one of them and `0` to all others.\n",
    "\n",
    "These generated columns are sometimes called _dummy variables_, and we will use the [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) function to perform this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (49):-\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'passed']\n"
     ]
    }
   ],
   "source": [
    "# Preprocess feature columns\n",
    "# Note: this preprocesses all columns include the \"target\" column which needs\n",
    "# to be converted from [\"yes\", \"no\"] to [1, 0]\n",
    "def preprocess_features(X):\n",
    "    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\n",
    "\n",
    "    # Check each column\n",
    "    for col, col_data in X.iteritems():\n",
    "        # If data type is non-numeric, try to replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "        # Note: This should change the data type for yes/no columns to int\n",
    "\n",
    "        # If still non-numeric, convert to one or more dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix=col)  # e.g. 'school' => 'school_GP', 'school_MS'\n",
    "\n",
    "        outX = outX.join(col_data)  # collect column(s) in output dataframe\n",
    "\n",
    "    return outX\n",
    "\n",
    "student_data = preprocess_features(student_data)\n",
    "print(\"Processed feature columns ({}):-\\n{}\".format(len(student_data.columns), list(student_data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature values:-\n",
      "   school_GP  school_MS  sex_F  sex_M  age  address_R  address_U  famsize_GT3  \\\n",
      "0          1          0      1      0   18          0          1            1   \n",
      "1          1          0      1      0   17          0          1            1   \n",
      "2          1          0      1      0   15          0          1            0   \n",
      "3          1          0      1      0   15          0          1            1   \n",
      "4          1          0      1      0   16          0          1            1   \n",
      "\n",
      "   famsize_LE3  Pstatus_A    ...     higher  internet  romantic  famrel  \\\n",
      "0            0          1    ...          1         0         0       4   \n",
      "1            0          0    ...          1         1         0       5   \n",
      "2            1          0    ...          1         1         0       4   \n",
      "3            0          0    ...          1         1         1       3   \n",
      "4            0          0    ...          1         0         0       4   \n",
      "\n",
      "   freetime  goout  Dalc  Walc  health  absences  \n",
      "0         3      4     1     1       3         6  \n",
      "1         3      3     1     1       3         4  \n",
      "2         3      2     2     3       3        10  \n",
      "3         2      2     1     1       5         2  \n",
      "4         3      2     1     2       5         4  \n",
      "\n",
      "[5 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "y_all = student_data[target_col]  # corresponding targets/labels\n",
    "X_all = student_data.drop([target_col], axis=1)  # feature values for all students\n",
    "print(\"\\nFeature values:-\")\n",
    "print(X_all.head())  # print the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and test sets\n",
    "\n",
    "So far, we have converted all _categorical_ features into numeric values. In this next step, we split the data (both features and corresponding labels) into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 300 samples\n",
      "Test set: 95 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "# First, decide how many training vs test samples you want\n",
    "num_all = student_data.shape[0]  # same as len(student_data)\n",
    "num_train = 300  # about 75% of the data\n",
    "num_test = num_all - num_train\n",
    "\n",
    "# TODO: Then, select features (X) and corresponding labels (y) for the training and test sets\n",
    "# Note: Shuffle the data or randomly select samples to avoid any bias due to ordering in the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, train_size=(num_train / num_all), random_state=99)\n",
    "\n",
    "print(\"Training set: {} samples\".format(X_train.shape[0]))\n",
    "print(\"Test set: {} samples\".format(X_test.shape[0]))\n",
    "# Note: If you need a validation set, extract bit from within training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluating Models\n",
    "Choose 3 supervised learning models that are available in scikit-learn, and appropriate for this problem. For each model:\n",
    "\n",
    "- What is the theoretical O(n) time & space complexity in terms of input size?\n",
    "- What are the general applications of this model? What are its strengths and weaknesses?\n",
    "- Given what you know about the data so far, why did you choose this model to apply?\n",
    "- Fit this model to the training data, try to predict labels (for both training and test sets), and measure the F<sub>1</sub> score. Repeat this process with different training set sizes (100, 200, 300), keeping test set constant.\n",
    "\n",
    "Produce a table showing training time, prediction time, F<sub>1</sub> score on training set and F<sub>1</sub> score on test set, for each training set size.\n",
    "\n",
    "Note: You need to produce 3 such tables - one for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0019099712371826172"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a model\n",
    "import time\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    return (end - start)\n",
    "\n",
    "# TODO: Choose a model, import it and instantiate an object\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=4)\n",
    "\n",
    "# Fit model to training data\n",
    "train_classifier(clf, X_train, y_train)  # note: using entire training set here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for training set: 0.8669724770642202\n"
     ]
    }
   ],
   "source": [
    "# Predict on training set and compute F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    return f1_score(target.values, y_pred), (end - start)\n",
    "\n",
    "train_f1_score = predict_labels(clf, X_train, y_train)\n",
    "print(\"F1 score for training set: {}\".format(train_f1_score[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for test set: 0.8029197080291971\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "print(\"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train and predict using different training set sizes\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    train_time = train_classifier(clf, X_train, y_train)\n",
    "    f1_train, prediction_time_train = predict_labels(clf, X_train, y_train)\n",
    "    f1_test, prediction_time_test, = predict_labels(clf, X_test, y_test)\n",
    "    return f1_train, f1_test, train_time, np.mean([prediction_time_train, prediction_time_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_classifier(clf, training_sizes=(100, 200, len(X_train))):\n",
    "    \"\"\"Evaluate and train a classifier. reports f1 score on train and test data,\n",
    "    as well as training and prediction time for various training sizes.\n",
    "    Uses the student data defined in the global namespace.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for k in training_sizes:\n",
    "        # data has already been shuffled, so we just use first k samples\n",
    "        f1_train, f1_test, train_time, prediction_time = train_predict(clf, X_train[:k], y_train[:k], X_test, y_test)\n",
    "        scores.append([k, f1_train, f1_test, train_time, prediction_time])\n",
    "\n",
    "    df = pd.DataFrame(scores, columns=['train_size', 'f1_train', 'f1_test', 'train_time', 'prediction_time'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model 1: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>train_time</th>\n",
       "      <th>prediction_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.816568</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>0.831746</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.000181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size  f1_train   f1_test  train_time  prediction_time\n",
       "0         100  0.816568  0.774194    0.000891         0.000208\n",
       "1         200  0.831746  0.802721    0.000513         0.000185\n",
       "2         300  0.810811  0.812030    0.000571         0.000181"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['failures']\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=1, random_state=99)\n",
    "\n",
    "display(train_and_evaluate_classifier(clf))\n",
    "print([x for x in X_all.columns[clf.feature_importances_ != 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the theoretical O(n) time & space complexity in terms of input size?\n",
    "> The sklearn implementation of a Decision Tree has a time complexity of [$O(D * n * log(n))$](http://scikit-learn.org/stable/modules/tree.html#complexity) where `D` is the number of features, and `n` is the number of samples. An $O(n * log(n))$ running time in the number of samples is relatively fast. Prediction times are very fast, taking `O(max_depth)`. Space complexity grows with the complexity of our tree, but will not exceed `D`. It can be limited with `max_depth`, as well as other parameters.\n",
    "\n",
    "- What are the general applications of this model? What are its strengths and weaknesses?\n",
    "> Decision trees are simple but robust classifiers. They can be easily visualized, and due to their simplicity they are very interpretable. Judging by our results above, they seems to perform reasonably well on small datasets. However, decision trees can also be prone to overfitting, which is why hyperparameter tuning is especially important. In this case we set `max_depth=2` to keep the implementation simple, and help us identify key features. Decision trees can also be very sensitive to outliers, where as little as one value can result in a completely different tree being generated.\n",
    "\n",
    "- Given what you know about the data so far, why did you choose this model to apply?\n",
    "> A Decision Tree Classifier was chosen for its simplicity and speed as a classifier. It is relatively easy to build and tune, and provides a quick way to identify the best splitting features and build a classifier. Identifying key splitting features in such a manner can simplify subsequent analysis. It seems as though 'failures' is the best feature to split on, and that we don't recieve benefit from splitting on other features thereafter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model 2: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>train_time</th>\n",
       "      <th>prediction_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.814371</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.002635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>0.815047</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.003920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>0.829569</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.006878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size  f1_train   f1_test  train_time  prediction_time\n",
       "0         100  0.814371  0.786667    0.002024         0.002635\n",
       "1         200  0.815047  0.781457    0.000803         0.003920\n",
       "2         300  0.829569  0.791946    0.000983         0.006878"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=25)\n",
    "\n",
    "display(train_and_evaluate_classifier(clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the theoretical O(n) time & space complexity in terms of input size?\n",
    "> KNN is very cheap to train, but query times can be more expensive. For a query, must identify the closest K neighbors, which involves sorting them by distance (which is also proportional to number of features, `D`). Therefore running time should be a worst case $O(D * n * log(n))$, assuming an algorithm like merge sort is used for sorting. Space complexity should never be more then `O(n)`, as all we need to do is keep track of our samples in memory.\n",
    "\n",
    "- What are the general applications of this model? What are its strengths and weaknesses?\n",
    "> KNN is another relatively simple algorithm that can easily be visualized and interpreted. However, performance can degrade at boundary conditions and when regions are not covered well with samples. Generally, we need a lot of data to cover our feature space; however, it appears that KNN performs very well on the test set even when trained on only 100 samples. However, if we are doing a lot of predictions compared to training, it may not be well suited for our task.\n",
    "\n",
    "- Given what you know about the data so far, why did you choose this model to apply?\n",
    "> The Decision Tree struggled and overfit quickly with `max_depth > 2`. We wanted to identify whether students would cluster in our feature space, as Decision Trees are not quite as good at identifying correlations across many features. KNN is a simple way to achieve this sort of clustering by performing a distance metric. It appears as though KNN achieves similar testing error on the data as the Decision Tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Boosted Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>train_time</th>\n",
       "      <th>prediction_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.019528</td>\n",
       "      <td>0.001905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.028531</td>\n",
       "      <td>0.002965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>0.829596</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.040533</td>\n",
       "      <td>0.002442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size  f1_train   f1_test  train_time  prediction_time\n",
       "0         100  0.885714  0.712121    0.019528         0.001905\n",
       "1         200  0.827586  0.746032    0.028531         0.002965\n",
       "2         300  0.829596  0.818182    0.040533         0.002442"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "est = DecisionTreeClassifier(max_depth=1)\n",
    "clf = AdaBoostClassifier(est, n_estimators=10)\n",
    "display(train_and_evaluate_classifier(clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the theoretical O(n) time & space complexity in terms of input size?\n",
    "> We decided to try to combine multiple decision tree classifiers in the form of boosting. The running time is simply the number of estimators `N` times the run time of each individual estimator. Since we are using decision trees, we can plug in our decision tree performance to get $O(N *D * n * log(n))$. The space complexity is similarly scaled by the number of estimators present, and depends on the max_depth of each tree: `O(N * max_depth)`.\n",
    "\n",
    "- What are the general applications of this model? What are its strengths and weaknesses?\n",
    "> Boosting tends to be very robust to overfitting, and often provides better results then individual decision tree classifiers. However, it results in high model complexity and can be harder to interpret, especially if there are many estimators in the model. The key to boosting is using 'weak' classifiers, so we set max_depth to one (which also provided the best results).\n",
    "\n",
    "- Given what you know about the data so far, why did you choose this model to apply?\n",
    "> KNN failed to perform better then the individual decision trees, so we decided to try Adaboost as it often performs better then a simple decision tree. The boosted tree performed slightly better then an individual tree, but not by much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Choosing the Best Model\n",
    "\n",
    "- Based on the experiments you performed earlier, in 1-2 paragraphs explain to the board of supervisors what single model you chose as the best model. Which model is generally the most appropriate based on the available data, limited resources, cost, and performance?\n",
    "- In 1-2 paragraphs explain to the board of supervisors in layman's terms how the final model chosen is supposed to work (for example if you chose a Decision Tree or Support Vector Machine, how does it make a prediction).\n",
    "- Fine-tune the model. Use Gridsearch with at least one important parameter tuned and with at least 3 settings. Use the entire training set for this.\n",
    "- What is the model's final F<sub>1</sub> score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After analysis of the data we determined the best predictive metric for success was the percent of failures students had. Adding other metrics failed to give us any better indicator of students at risk for failure. Students with a failure rate higher then `0.5` should be given extra help. The model we chose to assess this dataset was a decision tree, which is relatively simple to train, and very simple to predict. In fact, the best machine learning solution we found for this dataset is so simple it could be performed by a human. Therefore it will also be computationally inexpensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a prediction, the Decision Tree model looks at an individaul's failure rates, and flags them if they are greater than `0.5`. This was the best indicator of failure we found by looking at the dataset. There seems to be no correlation between other features and student success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>train_time</th>\n",
       "      <th>prediction_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.81203</td>\n",
       "      <td>5.40364</td>\n",
       "      <td>0.000323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size  f1_train  f1_test  train_time  prediction_time\n",
       "0         300  0.810811  0.81203     5.40364         0.000323"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "scorer = make_scorer(f1_score)\n",
    "\n",
    "params = {\n",
    "    'base_estimator': [DecisionTreeClassifier(max_depth=n) for n in [1, 2, 3, 4, 5, 10]],\n",
    "    'n_estimators': [1, 5, 10, 20, 50, 100],\n",
    "}\n",
    "\n",
    "reg = AdaBoostClassifier()\n",
    "\n",
    "clf = GridSearchCV(reg, param_grid=params, scoring=scorer)\n",
    "\n",
    "display(train_and_evaluate_classifier(clf, [len(X_train)]))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model's f1 score is `0.811` on the training data, and `0.812` on the testing data. Our testing and training scores are very similar, which indicates that we have little variance in this model. However, we could be over generalizing, as the data did not seem to provide us much insight beyond what would have been a logical decision (splitting on failure rate). Perhaps with more data we could better cover our feature space, and determine some correlation between other features.\n",
    "\n",
    "Note: Adaboost's best performance is actually with a single decision stump! Therefore we went with a single decision tree as our final model. Even though the `f1_test` score for `n_estimators=10` is better then that for `n_estimators=1`, the GridSearch determined that there is a lower training and cross-validation error with `n_estimators=1`. We should never use our testing data to make decisions about tuning our model, therefore we went with the lower cross-validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"258pt\" height=\"158pt\"\n",
       " viewBox=\"0.00 0.00 258.02 158.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 154)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-154 254.02,-154 254.02,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.537255\" stroke=\"black\" d=\"M174.87,-150C174.87,-150 79.0434,-150 79.0434,-150 73.0434,-150 67.0434,-144 67.0434,-138 67.0434,-138 67.0434,-98 67.0434,-98 67.0434,-92 73.0434,-86 79.0434,-86 79.0434,-86 174.87,-86 174.87,-86 180.87,-86 186.87,-92 186.87,-98 186.87,-98 186.87,-138 186.87,-138 186.87,-144 180.87,-150 174.87,-150\"/>\n",
       "<text text-anchor=\"start\" x=\"86.9287\" y=\"-134.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">failures ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"86.6724\" y=\"-120.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.4328</text>\n",
       "<text text-anchor=\"start\" x=\"81.2344\" y=\"-106.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 300</text>\n",
       "<text text-anchor=\"start\" x=\"75\" y=\"-92.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [95, 205]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.670588\" stroke=\"black\" d=\"M107.87,-50C107.87,-50 12.0434,-50 12.0434,-50 6.04343,-50 0.0434256,-44 0.0434256,-38 0.0434256,-38 0.0434256,-12 0.0434256,-12 0.0434256,-6 6.04343,-0 12.0434,-0 12.0434,-0 107.87,-0 107.87,-0 113.87,-0 119.87,-6 119.87,-12 119.87,-12 119.87,-38 119.87,-38 119.87,-44 113.87,-50 107.87,-50\"/>\n",
       "<text text-anchor=\"start\" x=\"19.6724\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.3718</text>\n",
       "<text text-anchor=\"start\" x=\"14.2344\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 239</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [59, 180]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M104.086,-85.9375C97.5364,-77.0413 90.3816,-67.3236 83.7761,-58.352\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"86.3965,-56.0077 77.649,-50.0301 80.7595,-60.158 86.3965,-56.0077\"/>\n",
       "<text text-anchor=\"middle\" x=\"73.8946\" y=\"-70.5466\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.305882\" stroke=\"black\" d=\"M238.084,-50C238.084,-50 149.83,-50 149.83,-50 143.83,-50 137.83,-44 137.83,-38 137.83,-38 137.83,-12 137.83,-12 137.83,-6 143.83,-0 149.83,-0 149.83,-0 238.084,-0 238.084,-0 244.084,-0 250.084,-6 250.084,-12 250.084,-12 250.084,-38 250.084,-38 250.084,-44 244.084,-50 238.084,-50\"/>\n",
       "<text text-anchor=\"start\" x=\"153.672\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.4837</text>\n",
       "<text text-anchor=\"start\" x=\"152.127\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 61</text>\n",
       "<text text-anchor=\"start\" x=\"145.893\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [36, 25]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M149.827,-85.9375C156.377,-77.0413 163.531,-67.3236 170.137,-58.352\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"173.154,-60.158 176.264,-50.0301 167.517,-56.0077 173.154,-60.158\"/>\n",
       "<text text-anchor=\"middle\" x=\"180.018\" y=\"-70.5466\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x10b8d9cf8>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image  \n",
    "import pydotplus as pydot\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "train_classifier(clf, X_train, y_train)\n",
    "\n",
    "fname = 'my_tree.dot'\n",
    "export_graphviz(clf, out_file=fname,  \n",
    "                feature_names=X_all.columns,  \n",
    "                filled=True, rounded=True,  \n",
    "                special_characters=True)\n",
    "import graphviz\n",
    "\n",
    "with open(fname) as f:\n",
    "    dot_graph = f.read()\n",
    "\n",
    "graphviz.Source(dot_graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
